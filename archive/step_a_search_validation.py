# ë¼í”„í…” ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ìš© ìŠ¤í¬ë¦½íŠ¸
# ê²€ìƒ‰ì–´ì™€ ì‹¤ì œ ë§¤ì¹­ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ì •í™•ì„± í™•ì¸
import csv
import laftel
import json

INPUT_CSV = "anime.csv"
VALIDATION_OUTPUT = "search_validation.json"
VALIDATION_CSV = "search_validation.csv"

def validate_search_results(title: str, max_results: int = 5):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ê³  ìƒì„¸ ì •ë³´ ë°˜í™˜"""
    print(f"ğŸ” '{title}' ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦:")
    print("-" * 50)
    
    try:
        results = laftel.sync.searchAnime(title)
        if not results:
            print(f"âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return {
                "search_query": title,
                "found_results": False,
                "result_count": 0,
                "candidates": []
            }
        
        print(f"âœ… ì´ {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
        
        candidates = []
        for i, result in enumerate(results[:max_results]):
            print(f"\nğŸ“º ê²°ê³¼ #{i+1}:")
            print(f"   ì œëª©: {result.name}")
            print(f"   ID: {result.id}")
            print(f"   ì¥ë¥´: {result.genres}")
            
            # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            try:
                info = laftel.sync.getAnimeInfo(result.id)
                episodes = laftel.sync.searchEpisodes(result.id)
                total_episodes = len(episodes) if episodes else 0
                
                candidate_info = {
                    "rank": i + 1,
                    "id": result.id,
                    "title": result.name,
                    "genres": result.genres,
                    "air_year_quarter": info.air_year_quarter or "",
                    "avg_rating": info.avg_rating or 0.0,
                    "status": "ì™„ê²°" if getattr(info, "ended", False) else "ë°©ì˜ì¤‘",
                    "production": info.production or "",
                    "total_episodes": total_episodes,
                    "laftel_url": info.url or "",
                    "similarity_score": calculate_similarity(title, result.name)
                }
                
                candidates.append(candidate_info)
                
                print(f"   ë°©ì˜ë¶„ê¸°: {candidate_info['air_year_quarter']}")
                print(f"   í‰ì : {candidate_info['avg_rating']}")
                print(f"   ìƒíƒœ: {candidate_info['status']}")
                print(f"   ì œì‘ì‚¬: {candidate_info['production']}")
                print(f"   ì´ í™”ìˆ˜: {candidate_info['total_episodes']}í™”")
                print(f"   ìœ ì‚¬ë„: {candidate_info['similarity_score']:.2f}")
                
            except Exception as e:
                print(f"   âŒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                candidates.append({
                    "rank": i + 1,
                    "id": result.id,
                    "title": result.name,
                    "genres": result.genres,
                    "error": str(e)
                })
        
        return {
            "search_query": title,
            "found_results": True,
            "result_count": len(results),
            "candidates": candidates,
            "recommended_choice": candidates[0] if candidates else None
        }
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {
            "search_query": title,
            "found_results": False,
            "result_count": 0,
            "error": str(e),
            "candidates": []
        }

def calculate_similarity(query: str, result_title: str):
    """ê°„ë‹¨í•œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
    query_clean = query.lower().replace(" ", "").replace(":", "").replace("-", "")
    result_clean = result_title.lower().replace(" ", "").replace(":", "").replace("-", "").replace("(", "").replace(")", "").replace("ã€", "").replace("ã€‘", "")
    
    # í¬í•¨ ê´€ê³„ í™•ì¸
    if query_clean in result_clean or result_clean in query_clean:
        return 0.8
    
    # ë‹¨ì–´ë³„ ë§¤ì¹­ í™•ì¸
    query_words = set(query.lower().split())
    result_words = set(result_title.lower().split())
    
    if query_words and result_words:
        intersection = query_words & result_words
        union = query_words | result_words
        return len(intersection) / len(union)
    
    return 0.0

def main():
    print("ğŸ” ë¼í”„í…” ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ ì‹œì‘!")
    print("=" * 70)
    
    all_validations = []
    validation_rows = []
    
    with open(INPUT_CSV, newline="", encoding="utf-8") as f:
        for i, row in enumerate(csv.DictReader(f)):
            query = (row.get("title") or "").strip()
            if not query:
                continue
                
            print(f"\n[{i+1}] ê²€ì¦ ì¤‘: {query}")
            validation_result = validate_search_results(query)
            all_validations.append(validation_result)
            
            # CSV ì¶œë ¥ìš© ë°ì´í„° ì¤€ë¹„
            if validation_result["found_results"] and validation_result["candidates"]:
                best_match = validation_result["candidates"][0]
                validation_rows.append({
                    "search_query": query,
                    "matched_title": best_match["title"],
                    "similarity": best_match.get("similarity_score", 0),
                    "air_year_quarter": best_match.get("air_year_quarter", ""),
                    "avg_rating": best_match.get("avg_rating", 0),
                    "status": best_match.get("status", ""),
                    "production": best_match.get("production", ""),
                    "total_episodes": best_match.get("total_episodes", 0),
                    "laftel_url": best_match.get("laftel_url", ""),
                    "result_count": validation_result["result_count"],
                    "needs_review": "âš ï¸" if best_match.get("similarity_score", 0) < 0.7 else "âœ…"
                })
            else:
                validation_rows.append({
                    "search_query": query,
                    "matched_title": "âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ",
                    "similarity": 0,
                    "needs_review": "âŒ"
                })
            
            print("=" * 70)
    
    # JSON í˜•íƒœë¡œ ìƒì„¸ ê²°ê³¼ ì €ì¥
    with open(VALIDATION_OUTPUT, "w", encoding="utf-8") as f:
        json.dump(all_validations, f, ensure_ascii=False, indent=2)
    
    # CSV í˜•íƒœë¡œ ìš”ì•½ ê²°ê³¼ ì €ì¥
    if validation_rows:
        with open(VALIDATION_CSV, "w", newline="", encoding="utf-8") as f:
            fieldnames = ["search_query", "matched_title", "similarity", "air_year_quarter", 
                         "avg_rating", "status", "production", "total_episodes", 
                         "laftel_url", "result_count", "needs_review"]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(validation_rows)
    
    print(f"\nğŸ‰ ê²€ì¦ ì™„ë£Œ!")
    print(f"ğŸ“‹ ìƒì„¸ ê²°ê³¼: {VALIDATION_OUTPUT}")
    print(f"ğŸ“Š ìš”ì•½ ê²°ê³¼: {VALIDATION_CSV}")
    
    # ê²€í†  í•„ìš”í•œ í•­ëª© ìš”ì•½
    needs_review = [row for row in validation_rows if row["needs_review"] in ["âš ï¸", "âŒ"]]
    if needs_review:
        print(f"\nâš ï¸ ê²€í†  í•„ìš”í•œ í•­ëª© {len(needs_review)}ê°œ:")
        for item in needs_review:
            print(f"   - '{item['search_query']}' â†’ '{item['matched_title']}'")
    else:
        print(f"\nâœ… ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ê°€ ì ì ˆí•©ë‹ˆë‹¤!")

if __name__ == "__main__":
    main()

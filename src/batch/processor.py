# ğŸ”„ ìƒˆë¡œìš´ ë°°ì¹˜ í”„ë¡œì„¸ì„œ (ì½”ì–´ ëª¨ë“ˆ ê¸°ë°˜)
"""
ë¦¬íŒ©í† ë§ëœ ë°°ì¹˜ ì²˜ë¦¬ê¸°
- AnimePipelineì„ ì‚¬ìš©í•˜ì—¬ í†µí•© ë¡œì§ í™œìš©
- ê¸°ì¡´ ë°°ì¹˜ ì²˜ë¦¬ ê¸°ëŠ¥ ìœ ì§€
- ì—ëŸ¬ ì²˜ë¦¬ ë° ê²°ê³¼ ì €ì¥ ê°œì„ 
"""

import os
import csv
import json
import time
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

from ..core.pipeline import AnimePipeline
from ..core.models import ProcessResult, ProcessStatus, BatchConfig, BatchSummary, create_error_result
from ..core.config import settings

class BatchProcessor:
    """ìƒˆë¡œìš´ ë°°ì¹˜ ì²˜ë¦¬ê¸° (ì½”ì–´ ëª¨ë“ˆ ê¸°ë°˜)"""
    
    def __init__(self, csv_file: str, description: str = "", notion_db_id: str = None):
        """
        ë°°ì¹˜ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            csv_file: ì²˜ë¦¬í•  CSV íŒŒì¼ ê²½ë¡œ
            description: ë°°ì¹˜ ì„¤ëª…
            notion_db_id: ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ID (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.csv_file = csv_file
        self.description = description
        
        # ë°°ì¹˜ ID ìƒì„± (ê¸°ì¡´ í˜•ì‹ ìœ ì§€)
        timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S")
        csv_name = Path(csv_file).stem
        self.batch_id = f"{timestamp}_{csv_name}_batch"
        
        # ê²°ê³¼ í´ë” ìƒì„±
        self.batch_folder = os.path.join("productions", self.batch_id)
        os.makedirs(self.batch_folder, exist_ok=True)
        
        # í•˜ìœ„ í´ë” ìƒì„± (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
        for subfolder in ['search_results', 'llm_results', 'metadata_results', 'notion_results']:
            os.makedirs(os.path.join(self.batch_folder, subfolder), exist_ok=True)
        
        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self.pipeline = AnimePipeline()
        
        # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (ë…¸ì…˜ DB ID)
        if notion_db_id:
            # TODO: ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ êµ¬í˜„
            pass
        
        print(f"ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        print(f"ğŸ“ ë°°ì¹˜ ID: {self.batch_id}")
        print(f"ğŸ“‚ ë°°ì¹˜ í´ë”: {self.batch_folder}")
    
    def load_anime_list(self) -> List[str]:
        """CSV íŒŒì¼ì—ì„œ ì• ë‹ˆë©”ì´ì…˜ ëª©ë¡ ë¡œë“œ"""
        anime_list = []
        
        try:
            with open(self.csv_file, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                
                # í—¤ë” ìŠ¤í‚µ
                header = next(reader, None)
                if header:
                    print(f"ğŸ“„ CSV í—¤ë”: {header}")
                
                # ì• ë‹ˆë©”ì´ì…˜ ì œëª©ë“¤ ë¡œë“œ
                for row in reader:
                    if row and row[0].strip():  # ë¹ˆ í–‰ ìŠ¤í‚µ
                        anime_list.append(row[0].strip())
                        
            print(f"ğŸ“‹ ì• ë‹ˆë©”ì´ì…˜ ëª©ë¡ ë¡œë“œ ì™„ë£Œ: {len(anime_list)}ê°œ")
            return anime_list
            
        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def save_batch_config(self, anime_list: List[str]) -> None:
        """ë°°ì¹˜ ì„¤ì • ì €ì¥"""
        config_data = {
            "batch_id": self.batch_id,
            "source_csv": self.csv_file,
            "description": self.description,
            "total_items": len(anime_list),
            "start_time": datetime.now().isoformat(),
            "notion_database_id": settings.notion_database_id
        }
        
        config_file = os.path.join(self.batch_folder, "batch_config.json")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, ensure_ascii=False, indent=2)
    
    def save_step_result(self, step_name: str, index: int, title: str, 
                        result_data: Dict[str, Any]) -> str:
        """ë‹¨ê³„ë³„ ê²°ê³¼ ì €ì¥"""
        folder_map = {
            "search": "search_results",
            "llm": "llm_results", 
            "metadata": "metadata_results",
            "notion": "notion_results"
        }
        
        subfolder = folder_map.get(step_name, step_name)
        filename = f"{step_name}_{index:02d}_{title}.json"
        filepath = os.path.join(self.batch_folder, subfolder, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                # datetime ê°ì²´ ìë™ ë¬¸ìì—´ ë³€í™˜
                json.dump(result_data, f, ensure_ascii=False, indent=2, default=str)
            return filepath
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def run_batch(self) -> bool:
        """ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            # ì• ë‹ˆë©”ì´ì…˜ ëª©ë¡ ë¡œë“œ
            anime_list = self.load_anime_list()
            if not anime_list:
                print("âŒ ì²˜ë¦¬í•  ì• ë‹ˆë©”ì´ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ë°°ì¹˜ ì„¤ì • ì €ì¥
            self.save_batch_config(anime_list)
            
            # ì‹¤í–‰ í†µê³„
            success_count = 0
            failed_count = 0
            processing_details = []
            
            print(f"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ")
            
            # ê° ì• ë‹ˆë©”ì´ì…˜ ì²˜ë¦¬
            for index, anime_title in enumerate(anime_list, 1):
                print(f"\n{'='*80}")
                print(f"ğŸ¯ [{index}/{len(anime_list)}] ì²˜ë¦¬ ì¤‘: {anime_title}")
                print(f"{'='*80}")
                
                item_start_time = time.time()
                
                try:
                    # í†µí•© íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬ (ë™ê¸° ë°©ì‹)
                    result = self._process_single_sync(anime_title)
                    
                    # ê²°ê³¼ë³„ ì²˜ë¦¬
                    if result.success:
                        print(f"âœ… ì „ì²´ ì²˜ë¦¬ ì„±ê³µ!")
                        success_count += 1
                    else:
                        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.error}")
                        failed_count += 1
                    
                    # ì²˜ë¦¬ ìƒì„¸ ì •ë³´ ì €ì¥
                    item_detail = {
                        "anime_title": anime_title,
                        "index": index,
                        "start_time": datetime.fromtimestamp(item_start_time).isoformat(),
                        "steps": self._extract_step_details(result, index, anime_title),
                        "final_status": "success" if result.success else "failed",
                        "end_time": datetime.now().isoformat()
                    }
                    
                    processing_details.append(item_detail)
                    
                    # ì§„í–‰ë¥  í‘œì‹œ
                    progress = (index / len(anime_list)) * 100
                    print(f"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% ({index}/{len(anime_list)})")
                    
                except KeyboardInterrupt:
                    print(f"\nâŒ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨ (ì²˜ë¦¬ ì™„ë£Œ: {index-1}/{len(anime_list)})")
                    break
                    
                except Exception as e:
                    print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                    failed_count += 1
                    
                    # ì‹¤íŒ¨ í•­ëª©ë„ ê¸°ë¡
                    item_detail = {
                        "anime_title": anime_title,
                        "index": index,
                        "start_time": datetime.fromtimestamp(item_start_time).isoformat(),
                        "steps": {},
                        "final_status": "failed",
                        "error": str(e),
                        "end_time": datetime.now().isoformat()
                    }
                    processing_details.append(item_detail)
                    continue
            
            # ë°°ì¹˜ ìš”ì•½ ì €ì¥
            total_time = time.time() - start_time
            
            summary = BatchSummary(
                batch_id=self.batch_id,
                execution_summary={
                    "total_items": len(anime_list),
                    "success_count": success_count,
                    "failed_count": failed_count,
                    "success_rate": f"{(success_count / len(anime_list) * 100):.1f}%"
                },
                step_statistics={
                    "step1_success": success_count,  # ì„±ê³µí•œ ê²ƒì€ ëª¨ë“  ë‹¨ê³„ í†µê³¼
                    "step2_success": success_count,
                    "step3_success": success_count,
                    "step4_success": success_count
                },
                failed_items=[item["anime_title"] for item in processing_details if item["final_status"] == "failed"],
                processing_details=processing_details
            )
            
            summary_file = os.path.join(self.batch_folder, "batch_summary.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ ë³€í™˜
                summary_data = summary.dict()
                # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                if 'execution_time' in summary_data:
                    if hasattr(summary_data['execution_time'], 'isoformat'):
                        summary_data['execution_time'] = summary_data['execution_time'].isoformat()
                
                json.dump(summary_data, f, ensure_ascii=False, indent=2, default=str)
            
            # ìµœì¢… ê²°ê³¼ ì¶œë ¥
            print(f"\n{'='*80}")
            print(f"ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"ğŸ“ ê²°ê³¼ í´ë”: {self.batch_folder}")
            print(f"ğŸ“ˆ ì„±ê³µë¥ : {(success_count / len(anime_list) * 100):.1f}%")
            print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
            print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
            print(f"ğŸ’¾ ìš”ì•½ íŒŒì¼: {summary_file}")
            
            import datetime as dt
            duration = str(dt.timedelta(seconds=int(total_time)))
            print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {duration}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def _process_single_sync(self, title: str) -> ProcessResult:
        """ë‹¨ì¼ ì• ë‹ˆë©”ì´ì…˜ ë™ê¸° ì²˜ë¦¬ (íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ë°©ì‹ ê°œì„ )"""
        try:
            # ë‹¨ê³„ë³„ ì§ì ‘ í˜¸ì¶œ (ë¹„ë™ê¸° ë¬¸ì œ í•´ê²°)
            
            # Step 1: ë¼í”„í…” ê²€ìƒ‰
            print(f"\nğŸ” Step 1: ê²€ìƒ‰ í›„ë³´ ìˆ˜ì§‘")
            search_result = self.pipeline.laftel.search_anime(title)
            
            if not search_result.success or not search_result.candidates:
                # ë¹ˆ ë…¸ì…˜ í˜ì´ì§€ ìƒì„±
                notion_result = self.pipeline.notion.create_or_update_page(title, None)
                return ProcessResult(
                    title=title,
                    success=notion_result.success,
                    status=ProcessStatus.PARTIAL_SUCCESS if notion_result.success else ProcessStatus.FAILED,
                    notion_url=notion_result.page_url if notion_result.success else None,
                    error="ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ë¹ˆ í˜ì´ì§€ë§Œ ìƒì„±ë¨",
                    steps_completed=1 if notion_result.success else 0
                )
            
            print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: {len(search_result.candidates)}ê°œ í›„ë³´ ìˆ˜ì§‘ ì„±ê³µ")
            
            # Step 2: AI ë§¤ì¹­
            print(f"\nğŸ¤– Step 2: LLM ë§¤ì¹­") 
            llm_result = self.pipeline.openai.find_best_match(title, search_result.candidates)
            
            if not llm_result.success or not llm_result.selected_title:
                # ì²« ë²ˆì§¸ í›„ë³´ë¡œ í´ë°±
                if search_result.candidates:
                    llm_result.selected_title = search_result.candidates[0].title
                    llm_result.success = True
                    print(f"âš ï¸ AI ë§¤ì¹­ ì‹¤íŒ¨ - ì²« ë²ˆì§¸ í›„ë³´ ì„ íƒ: {llm_result.selected_title}")
                else:
                    return create_error_result(title, f"Step 2 ì‹¤íŒ¨: {llm_result.error_message}", 1)
            
            print(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: ë§¤ì¹­ ì„±ê³µ")
            
            # Step 3: ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            print(f"\nğŸ“Š Step 3: ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘")
            metadata_result = self.pipeline.laftel.get_metadata(llm_result.selected_title)
            
            if not metadata_result.success:
                print("âš ï¸ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - ê¸°ë³¸ ì •ë³´ë§Œìœ¼ë¡œ ì§„í–‰")
            else:
                print(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
            
            # Step 4: ë…¸ì…˜ ì—…ë¡œë“œ
            print(f"\nğŸ“ Step 4: ë…¸ì…˜ ì—…ë¡œë“œ")
            metadata_obj = metadata_result.metadata if metadata_result.success else None
            notion_result = self.pipeline.notion.create_or_update_page(title, metadata_obj)
            
            if not notion_result.success:
                return create_error_result(title, f"Step 4 ì‹¤íŒ¨: {notion_result.error_message}", 3)
            
            print(f"âœ… 4ë‹¨ê³„ ì™„ë£Œ: ë…¸ì…˜ ì—…ë¡œë“œ ì„±ê³µ")
            
            # ìµœì¢… ì„±ê³µ ê²°ê³¼
            return ProcessResult(
                title=title,
                success=True,
                status=ProcessStatus.SUCCESS,
                notion_url=notion_result.page_url,
                search_result=search_result,
                llm_result=llm_result,
                metadata_result=metadata_result,
                notion_result=notion_result,
                steps_completed=4
            )
            
        except Exception as e:
            error_msg = f"ë‹¨ì¼ ì• ë‹ˆë©”ì´ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            print(f"âŒ {error_msg}")
            return create_error_result(title, error_msg, 0)
    
    def _extract_step_details(self, result: ProcessResult, index: int, title: str) -> Dict[str, Any]:
        """ë‹¨ê³„ë³„ ê²°ê³¼ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° íŒŒì¼ ì €ì¥"""
        steps = {}
        
        # Step 1: ê²€ìƒ‰ ê²°ê³¼
        if result.search_result:
            search_data = result.search_result.dict()
            search_file = self.save_step_result("search", index, title, search_data)
            steps["step1"] = {
                "success": result.search_result.success,
                "file": search_file,
                "candidates_count": len(result.search_result.candidates)
            }
        
        # Step 2: LLM ê²°ê³¼
        if result.llm_result:
            llm_data = result.llm_result.dict()
            llm_file = self.save_step_result("llm", index, title, llm_data)
            steps["step2"] = {
                "success": result.llm_result.success,
                "file": llm_file,
                "match_status": "match_found" if result.llm_result.selected_title else "no_match"
            }
        
        # Step 3: ë©”íƒ€ë°ì´í„° ê²°ê³¼
        if result.metadata_result:
            metadata_data = result.metadata_result.dict()
            metadata_file = self.save_step_result("metadata", index, title, metadata_data)
            steps["step3"] = {
                "success": result.metadata_result.success,
                "file": metadata_file
            }
        
        # Step 4: ë…¸ì…˜ ê²°ê³¼  
        if result.notion_result:
            notion_data = result.notion_result.dict()
            notion_file = self.save_step_result("notion", index, title, notion_data)
            steps["step4"] = {
                "success": result.notion_result.success,
                "file": notion_file,
                "notion_page_url": result.notion_result.page_url
            }
        
        return steps

# === í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë ˆê±°ì‹œ ë˜í¼ ===

def create_batch_processor(csv_file: str, description: str = "", notion_db_id: str = None):
    """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±ì„ ìœ„í•œ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return BatchProcessor(csv_file, description, notion_db_id)
